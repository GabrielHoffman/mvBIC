
---
title: "Power analysis for mvIC"
subtitle: ''
author: "Developed by [Gabriel Hoffman](http://gabrielhoffman.github.io/)"
date: "Run on `r Sys.time()`"
documentclass: article
output: 
  html_document:
  toc: true
  smart: false
vignette: >
  %\VignetteIndexEntry{Gene set enrichment from genomic intervals}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\usepackage[utf8]{inputenc}
---

<!--- 
# devtools::install_github('GabrielHoffman/pinnacle', auth_token='f74018151cf7c902b57aa023b2737190e9bc0400')

R CMD INSTALL -l $R_LIBS_USER ../

source ~/.bash_profile
cd /hpc/users/hoffmg01/build2/mvIC/vignette
module load R/3.6.0 pandoc openssl boost git
git pull origin dev
alias R='R --quiet --no-save --no-restore-data'
R

# Sys.setenv(GITHUB_PAT = "f74018151cf7c902b57aa023b2737190e9bc0400")

devtools::reload("/Users/gabrielhoffman/workspace/repos/mvIC")



rmarkdown::render("sims.Rmd", output_dir='./', intermediates_dir='./')



# run analysis
# cd /Users/gabrielhoffman/workspace/repos/mvIC/vignettes
# cd /hpc/users/hoffmg01/build2/mvIC/vignettes

# rm -fr sims_*
 --->

```{r load.packages, echo=FALSE, message=FALSE, results='hide'}
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(data.table))
suppressPackageStartupMessages(library(mvIC))
suppressPackageStartupMessages(library(variancePartition))

options(xtable.type="html")

setDTthreads(3, restore_after_fork=FALSE)

knitr::opts_chunk$set(
  echo=FALSE,
  warning=FALSE,
  message=FALSE,
  error = FALSE,
  tidy = FALSE,
  cache = TRUE,
  cache.lazy = FALSE,  dev = c("png", "pdf"), 
  fig.width=7, fig.height=7)

options(markdown.HTML.stylesheet = 'css/custom.css')
```

do EpiMap GEUVADIS, SEQC, GTEX, CMCv2 + simulations
add single cell, and EHR
Compare to summing standard BIC

Simulation, show probability of selection true model increases with number of features 
# compare to sum of BIC

Compare with "standard" Multivariate AIC, AICc, BIC for n > p

with high signam, why do other perform better?  Is that an issue with the randomization of the simulations???

add AICc from see Yanagihara, et al. 2015
    # doi:10.1214/15-EJS1022

How did the do simulations?
exhaustive search?    
Do best subset selection for combn(10, k) 1:5
  evaluate average rank of best model
  and probability that true model is best scoring?






devtools::reload("/Users/gabrielhoffman/workspace/repos/mvIC")


```{r basic}
n = 100
p = 10
m_active = 1
X = matrix(rnorm(n*p), n, p)
colnames(X) = paste0('X_', 1:p)
beta = matrix(rnorm(m_active*p, 10), m_active,p)
Noise = matrix(rnorm(n*p), n, p)
Y = X[,1:m_active] %*% beta + Noise
trueSet = sort(colnames(X)[1:m_active])

bestModel = mvForwardStepwise( t(Y), ~1, X, colnames(X))

bestModelNaive = mvForwardStepwise( t(Y), ~1, X, colnames(X), criterion="sum BIC")
```

```{r best.subset}

bestsubset_search = function(Y, data, variables, maxk=5){

  res = lapply( 1:maxk, function(k){
    idx = combn(length(variables), k)

    formArray = apply(idx, 2, function(i) paste('Y ~', paste(variables[i], collapse=' + ')))

    res = lapply(formArray, function(form){
      fit = lm(as.formula(form), data=data)

      res = lapply(c("EB", "var_unequal", "none"), function(method){
        res = lapply(c("AIC", "BIC", "sum AIC", "sum BIC"), function(criterion){
          if( length(grep("sum", criterion)) > 0 & method != "none" ) return(NULL)

          score = mvIC(fit, shrink.method=method, criterion=criterion)
          data.frame(k=k,form=form, method=method, criterion=criterion, score = score[1], stringsAsFactors=FALSE)
        })
        do.call(rbind, res)
      })
      do.call(rbind, res)
    } )
    res = do.call(rbind, res)
  })
  data.table(do.call(rbind, res))
}


library(poolr)
library(mvIC)
library(ggplot2)
library(mvtnorm)
library(data.table)
library(CVTuningCov)
library(Matrix)
library(gridExtra)
library(TAS)

set.seed(1)

n_reps = 10   
n = 50 # number of samples
m_total = 8 # total number of variables
# n_clusters = 5

m_active_array = 1
signalFraction = .5 #seq(.2, .8, by=.2)
ngenes_array = c(10, 100)
rho_array = seq(0, .98, length.out=8)


resSearch = lapply(1:n_reps, function(k){
    
  set.seed(k)

  resSearch = lapply(m_active_array, function(m_active){

    # simulate variables
    X = matrix(rnorm(m_total*n), n, m_total)
    colnames(X) = paste0('X_', 1:m_total)
    trueSet = c('1', sort(colnames(X)[1:m_active]))

    resSearch = lapply(ngenes_array, function(p){

        # simulate coefficient for each gene
        beta = matrix(rnorm(p*m_active, 0, 10), m_active,p)
        # beta[sample.int(length(beta), length(beta)*.5)] = 0 

        eta = X[,1:m_active,drop=FALSE] %*% beta 

        # changes correlation structure of noise. 
        clustID = sample.int(n_clusters, p, prob = dexp(1:n_clusters, .5), replace=TRUE)

        resSearch = lapply( rho_array, function(rho){

          # sigList = lapply(unique(clustID), function(id){
          #   count = sum(clustID == id)                
          #   Sigma = matrix(rho, count, count)
          #   diag(Sigma) = 1
          #   Sigma
          #   })
          # Sigma = as.matrix(bdiag(sigList))
          Sigma = matrix(rho, p, p)
          diag(Sigma) = 1
          # Sigma = AR1(p, rho)
          Noise = rmvnorm(n, sig=Sigma)

          resSearch = lapply(signalFraction, function(sigFrac){

            fctr = mean(apply(eta,1, var)) * (1-sigFrac)/sigFrac
            Y = eta + Noise*fctr
            # cor(eta[1,], eta[1,] + Noise[1,]*fctr)^2

            message("\rk = ", k, '  p = ', p, ' rho = ', round(rho,2), ' sigFrac = ', sigFrac,  ' m_active = ', m_active, '        ') 
 
            modelSearch = bestsubset_search(Y, as.data.frame(X), colnames(X), maxk=4)

            trueModel = paste('Y ~', paste(colnames(X)[1:m_active], collapse=' + ')) 

            # get best model
            # modelSearch[,form[which.min(score)],by=c('method', 'criterion')]

            # get best model
            df = modelSearch[,data.frame(rank = order(score), isTrue = form==trueModel) ,by=c('method', 'criterion')]

            # rank of best model
            res = df[isTrue==TRUE,1:3]
            res$k = k 
            res$m_active = m_active
            res$p = p
            res$rho = rho
            res$sigFrac = sigFrac
            res
          })
          do.call(rbind, resSearch)
        })
        do.call(rbind, resSearch)
      })
      do.call(rbind, resSearch)
    })
    do.call(rbind, resSearch)
})
resSearch = do.call(rbind, resSearch)
resSearch = data.table(resSearch)

```

```{r plot.model.search}

df = data.frame(resSearch[, data.frame(rank=mean(rank), sd=sd(rank)),by=c('method', 'criterion', 'm_active', 'p', 'rho', 'sigFrac')])

maxRank = max(df$rank)


figList = lapply(unique(df$sigFrac), function(v){
  ggplot( subset(df, sigFrac == v), aes(rho, rank, color=paste(method, criterion), fill=paste(method, criterion))) + geom_point() + geom_line() + geom_ribbon(aes(rho, ymin=pmax(rank-sd,0), ymax=pmin(rank+sd, maxRank)), alpha=.2, linetype=0) + facet_wrap( ~ m_active + p, nrow=1) + scale_color_discrete("Method") + scale_fill_discrete("Method") + theme_bw() + theme(aspect.ratio=1) + ggtitle(v) + scale_y_log10()
})

do.call("grid.arrange", c(figList, ncol=1))




```


```{r, cache=FALSE}
knit_exit()
```


```{r sim.scale}
library(poolr)
library(mvIC)
library(ggplot2)
library(mvtnorm)
library(data.table)
library(CVTuningCov)
library(Matrix)
library(gridExtra)
library(TAS)

set.seed(1)

n_reps = 10   
n = 50 # number of samples
# p = 10 # number of genes
# m_active = 2 # number of variables affecting phenotype
m_total = 10 # total number of variables
n_clusters = 5

m_active_array = 1#c(1, 2)
signalFraction = .6#seq(.4, .8, by=.2)
ngenes_array = c(100)#, 20, 40, 60, 80, 100, 200, 500)
rho_array = seq(0, .98, length.out=3)


# n_reps = 10
# n = 50 # number of samples
# m_active_array = 1
# signalFraction = .65# seq(.5, .7, length.out=3)
# ngenes_array = c(5, 20)#, 50, 100, 200)#, 25, 30, 40, 50)
# rho_array = seq(0, .98, length.out=4)


resRecovery = lapply(1:n_reps, function(k){
    
  set.seed(k)

  resRecovery = lapply(m_active_array, function(m_active){

    # simulate variables
    X = matrix(rnorm(m_total*n), n, m_total)
    colnames(X) = paste0('X_', 1:m_total)
    trueSet = c('1', sort(colnames(X)[1:m_active]))

    resRecovery = lapply(ngenes_array, function(p){

        # simulate coefficient for each gene
        beta = matrix(rnorm(p*m_active, 0, 10), m_active,p)
        # beta[sample.int(length(beta), length(beta)*.5)] = 0 

        eta = X[,1:m_active,drop=FALSE] %*% beta 

        # changes correlation structure of noise. 
        clustID = sample.int(n_clusters, p, prob = dexp(1:n_clusters, .5), replace=TRUE)

        resRecovery = lapply( rho_array, function(rho){

          sigList = lapply(unique(clustID), function(id){
            count = sum(clustID == id)                
            Sigma = matrix(rho, count, count)
            diag(Sigma) = 1
            Sigma
            })
          Sigma = as.matrix(bdiag(sigList))
          # Sigma = matrix(rho, p, p)
          diag(Sigma) = 1
          # Sigma = AR1(p, rho)
          Noise = rmvnorm(n, sig=Sigma)

          resRecovery = lapply(signalFraction, function(sigFrac){

            fctr = mean(apply(eta,1, var)) * (1-sigFrac)/sigFrac
            Y = eta + Noise*fctr
            # cor(eta[1,], eta[1,] + Noise[1,]*fctr)^2

            message("\rk = ", k, '  p = ', p, ' rho = ', round(rho,2), ' sigFrac = ', sigFrac,  ' m_active = ', m_active, '        ') 

            # save(list=ls(), file="test.RDATA") 

            # Multivariate methods
            methods = c(  "EB" ) #"var_equal",
            if( n > p){
               methods = c(methods, "none") 
            }
            criteria = c("AIC", "BIC") 
            res = lapply( methods, function(method){
              res = lapply( criteria, function(criterion){
                bestModel = mvForwardStepwise( t(Y), ~1, X, colnames(X), criterion=criterion, verbose=FALSE, shrink.method=method)

                # test of selected set is the true set  
                vars = subset(bestModel$trace, isAdded == "yes")$variable
                vars = as.character(vars)
                data.frame(criterion, 
                        method, 
                        recovery = identical( sort(vars), trueSet), 
                        rho = rho,
                        k = k,
                        p = p,
                        sigFrac = sigFrac,
                        m_active = m_active,stringsAsFactors=FALSE)
                })
              do.call(rbind, res)
             })
            res = do.call(rbind, res) 
          
            # sum scores for each response
            resSum = lapply(c("AIC", "BIC"), function(criterion){
               # fit naive model
              bestModelNaive = mvForwardStepwise( t(Y), ~1, X, colnames(X), criterion=paste("sum", criterion), verbose=FALSE, deltaCutoff=5)

              # test of selected set is the true set
              vars = subset(bestModelNaive$trace, isAdded == "yes")$variable
              vars = as.character(vars)
              result_naive = identical( sort(vars), trueSet)

              df_add = data.frame( criterion = "criterion", 
                          method = paste("sum", criterion),
                          recovery = result_naive,
                          rho = rho,
                          k = k,
                          p = p,
                          sigFrac = sigFrac,
                          m_active = m_active)
            })
            resSum = do.call(rbind, resSum)            

            rbind(res, resSum)
          })
          do.call(rbind, resRecovery)
        })
        do.call(rbind, resRecovery)
      })
      do.call(rbind, resRecovery)
    })
    do.call(rbind, resRecovery)
})
resRecovery = do.call(rbind, resRecovery)
resRecovery = data.table(resRecovery)
```

```{r plot.sims, cache=FALSE, fig.width=20, fig.height=30}
# summarize 
df = resRecovery[,data.frame(recoveryRate = sum(recovery)/length(recovery)),by=c('rho', 'p', 'sigFrac', 'm_active','method', 'criterion')]
df$sd = with(df, sqrt(recoveryRate*(1-recoveryRate)/n_reps))
df$up = with(df, recoveryRate + sd)
df$down = with(df, recoveryRate - sd)

df = df[grep("var_", method, invert=TRUE),]
# cols = c("red", "orange", "dodgerblue", "blue",  "navy", "grey", "green", "black")

figList = lapply(unique(df$sigFrac), function(v){
ggplot(subset(df, sigFrac==v), aes(rho, recoveryRate, color=paste(criterion, '-', method), fill=paste(criterion, '-', method))) + geom_ribbon(aes(ymin=down, ymax=up), alpha=.3, linetype=0) + geom_line() + geom_point() + scale_color_discrete("Method" ) + scale_fill_discrete("Method" ) + xlab(bquote(Correlation~(rho))) + ylab("Power to recover true model") + theme_bw() + theme(aspect.ratio=1) + ylim(0, 1) + facet_wrap(~m_active+p, ncol=length(ngenes_array)  ) + ggtitle(v)
})

# pdf("~/www/mvIC.pdf", width=12, height=120)
do.call("grid.arrange", c(figList, ncol=1))
# dev.off()

```

<!---

# naive
mvIC_fit( t(Y), ~ 1, X, criterion="sum BIC")
mvIC_fit( t(Y), ~ X_1, X, criterion="sum BIC")

method = "none"
# method="EB"
res1 = mvIC_fit( t(scale(Y)), ~ X_1, X, shrink.method=method, criterion="AIC")
res2 = mvIC_fit( t(scale(Y)), ~ 1, X, , shrink.method=method, criterion="AIC")
res1-res2
res1@params
res2@params


with(res1@params, dataTerm + 2 * (p*(m-1) + df_cov))[1]
with(res2@params, dataTerm + 2 * (p*(m-1) + df_cov))[1]



residMatrix1 = t(residuals(lm(scale(Y) ~ X_1, data=as.data.frame(X))))
residMatrix2 = t(residuals(lm(scale(Y) ~ 1, data=as.data.frame(X))))


res1 = rlogDet( residMatrix1, shrink.method="var_unequal" )
res2 = rlogDet( residMatrix2, shrink.method="var_unequal" )
res1 - res2

resA = rlogDet( residMatrix1, shrink.method="var_equal" )
resB = rlogDet( residMatrix2, shrink.method="var_equal" )
resA - resB


res = shrinkcovmat.unequal(residMatrix1)
plotCorrMatrix(Sigma, sort="none", dendrogram="none")
plotCorrMatrix(res$Sigmasample, sort="none", dendrogram="none")
plotCorrMatrix(res$Sigmahat, sort="none", dendrogram="none")


res = lapply(seq(0, .99, length.out=20), function(rho){
  Sigma = matrix(rho, p, p)
  diag(Sigma) = 1
  Noise = rmvnorm(n, sig=Sigma)
  # fctr = mean(apply(eta,1, var)) * (1-sigFrac)/sigFrac
  # Y = eta + Noise*fctr
  Y = Noise*fctr
  residMatrix1 = t(residuals(lm(scale(Y) ~ X_1, data=as.data.frame(X))))
  residMatrix2 = t(residuals(lm(scale(Y) ~ 1, data=as.data.frame(X))))

  f1 = shrinkcovmat.unequal( residMatrix1 )
  f2 = shrinkcovmat.unequal( residMatrix2 )

  a = gcShrink( residMatrix1, var=3, cor=1, plot=FALSE)
  b = gcShrink( residMatrix1, var=2, cor=1, plot=FALSE)

  data.frame(rho,
            true = sum(log(eigen(Sigma, only.values=TRUE)$values)),
            shrinkCovmat = sum(log(eigen(f1$Sigmahat, only.values=TRUE)$values)),
            gcShrink = sum(log(eigen(a$sigmahat, only.values=TRUE)$values)),
            gcShrink_eq = sum(log(eigen(b$sigmahat, only.values=TRUE)$values)))
        

  # data.frame( rho = rho, 
  #             lambda1 = f1$lambdahat,
  #             lambda2 = f2$lambdahat,
  #             lambda_strimmer = attr(cov.shrink(t(residMatrix1), lambda.var=0, verbose=FALSE),"lambda"), 
  #             alpha = a$optimalpha, 
  #             alpha_equal = b$optimalpha   )
})
res = do.call(rbind, res)

df = melt(res, id.var="rho")

ggplot(df, aes(rho, value, color=variable)) + geom_line() + theme_bw() + theme(aspect.ratio=1) + geom_vline(xintercept=.14, linetype="dashed")




mvIC:::mvIC_from_residuals( residMatrix1, 3, logDetMethod="var_unequal")
mvIC:::mvIC_from_residuals( residMatrix2, 2, logDetMethod="var_unequal"  )



rlogDet( residMatrix1, method="var_unequal" )
rlogDet( residMatrix2, method="var_unequal" )

rlogDet( residMatrix1, method="var_equal" )
rlogDet( residMatrix2, method="var_equal" )

rlogDet( residMatrix1, method="Str" )
rlogDet( residMatrix2, method="Str" )

rlogDet( residMatrix1, method="pseudo" )
rlogDet( residMatrix2, method="pseudo" )

d1 = svd(residMatrix1)$d^2 
d2 = svd(residMatrix2)$d^2 
# plot(d1, d2, log="xy")

a = sum(log(d1))
b = sum(log(d2))

v = sapply( 1:100, function(k){
  a = sum(log(d1[1:k]))
  b = sum(log(d2[1:k]))
  a-b
})
plot(v)

t(Y), ~1, X, colnames(X)



d1[1:3]
adjusted_eigen_values(residMatrix1, method="p")[1:3]


d1 = d1[1:99]
d2 = d2[1:99]

sum(log(d1))*100 - sum(log(d2))*100




res = shrinkcovmat.equal_lambda( residMatrix2 )
# lambda = res$lambda_hat
lambda = 0.3707678
ev_return = (1-lambda) * ev + lambda * res$nu_hat





library(denoiseR)

sig = estim_sigma(residMatrix1, method = "MAD")

res1 = optishrink( residMatrix1, sigma = sig, method = "ASYMPT", k=ncol(residMatrix1)-1)
sum(log(res1$singval^2))

res2 = optishrink( residMatrix2, sigma = sig, method = "ASYMPT", k=ncol(residMatrix1)-1)
sum(log(res2$singval^2))

plot(svd(residMatrix1)$d, svd(residMatrix2)$d)
plot(res1$singval[1:19], res2$singval[1:19])
abline(0,1, col="red")

# Compute delta BIC directly


res = optishrink( residMatrix1 - residMatrix2, method="ASYMPT")

d = svd(residMatrix1 - residMatrix2)$d
sum(2*log(d[1]))

d1 = svd(residMatrix1)$d^2
d2 = svd(residMatrix2)$d^2
adjusted_eigen_values( residMatrix1, method = "p")[1:3]


sum(log(d1)) - sum(log(d2)) 


C = tcrossprod(residMatrix2)
eigen(C)$values[1:4]

svd(residMatrix2)$d[1:4]^2






res = shrinkcovmat.identity(residMatrix1)
str(res)








bestModel = mvForwardStepwise( t(Y), ~1, X, colnames(X)[1:10])

method = "rlogDet"

a = mvIC_fit(t(Y), ~ X_3 , X, verbose=TRUE, logDetMethod = method)
b = mvIC_fit(t(Y), ~ X_10 + X_5 + X_9, X, verbose=TRUE, logDetMethod = method)
as.numeric(a - b)    


a = mvIC_fit(t(svd(Y)$u), ~ X_3 , X, verbose=TRUE, logDetMethod = method)
b = mvIC_fit(t(svd(Y)$u), ~ X_10 + X_5 + X_9, X, verbose=TRUE, logDetMethod = method)
as.numeric(a - b)    


a = mvIC_fit(t(svd(Y)$u), ~ X_3 , X, verbose=TRUE, usemvIC=FALSE, logDetMethod = method)
b = mvIC_fit(t(svd(Y)$u), ~ X_10 + X_5 + X_9, X, verbose=TRUE, usemvIC=FALSE, logDetMethod = method)
as.numeric(a - b)    




library(maotai)

n = 5
p = 10
Y = matrix(rnorm(n*p), n, p)

evalues = svd(Y)$d^2
sum(log(evalues[evalues > 1e-10]))

C = crossprod(Y)
evalues = eigen(C)$values
sum(log(evalues[evalues > 1e-10]))

log(pdeterminant(C))





n = 1000
p = 50
A = cor(matrix(rnorm(p*n),ncol=n))   # (n x n) matrix
k = as.double(Matrix::rankMatrix(A)) # rank of A


evalues = eigen(A)$values
pdet = sum(log(evalues[evalues > 1e-5]))

# smallest eigen-value
# (1-sqrt(n/p))^2
# evalues[p-1]

# x = p:n
# plot(x, (1-sqrt(n/x))^2)

# iterative computation
ntry = 11
del.vec = exp(-(1:ntry))
det.vec = rep(0,ntry)
for (i in 1:ntry){
  del = del.vec[i]
  # det.vec[i] = det(A+del*diag(n))/(del^(n-k))
  det.vec[i] = determinant(A+diag(del,n))$modulus[1] - (n-k)*log(del)
}

# visualize the results
opar <- par(no.readonly=TRUE)
plot(log(del.vec), det.vec, main=paste("true rank is ",k," out of ",n,sep=""),"b", xlab="iterations")
abline(h=pdet,col="red",lwd=1.2)
par(opar)


min(eigen(A+diag(del,n))$values)



finite sample size estimator for log det


n = 200

res = lapply( seq(20, 5*n, length.out=10), function(p){

  logDet = sapply(1:10, function(i){
    A = cor(matrix(rnorm(p*n),ncol=n))  
    determinant(A)$modulus[1]
    })
  data.frame(logDet, p)
})
res = do.call(rbind, res)

ggplot(res, aes(p, logDet)) + geom_point() + theme_bw()


library(corpcor)
library(HiDimDA)

n = 500
p = 30
X = matrix(rnorm(p*n),ncol=n)
A = cor(X)   # (n x n) matrix

res = ShrnkSigE( df=p-1, n, min(n,p-1), Sigma=A, Trgt = "Idntty")
res$Intst

evalues = eigen(A)$values
sum(log(evalues[evalues > 1e-10]))

sum(log(res$D))

sum(log(eigen(res)$values))

plot(eigen(A)$values, eigen(res)$values)

C = cov2cor(A)
ev = eigen(C)$values

get_lambda = function(ev, n, p){
  a = sum(ev^2) + sum(ev)^2
  b = n * sum(ev^2) + (p-n+1)/p * sum(ev)^2
  a / b
}
lambda = get_lambda(ev, n, p)

sum(log(ev*(1-lambda) + lambda))

sum(log(ev))


estimate.lambda(X)
 c = cor.shrink(X)
 attr(c, "lambda")



library(clusterGeneration)
library(mvtnorm)
library(corpcor)
library(HiDimDA)
library(TAS)
library(ShrinkCovMat)
library(ggplot2)
library(reshape2)
library(Rfast)



estLogDet = function( X, method, scale=TRUE){
  
  p = nrow(X)
  n = ncol(X)

  if( scale ){
      # A = cor(X)   # (n x n) matrix
    X_std = scale(X)/sqrt(p-1)
  }else{
    X_std = X
  }

  rnk = min(n, p-1)
  # ev = eigen(A)$values
  ev = svd(X_std)$d[1:rnk]^2

  if( method == "Strimmer"){
    lambda = estimate.lambda(X, verbose=FALSE)
    ev_shrink = (ev*(1-lambda) + lambda)
    ev_hat = c(ev_shrink, rep(lambda, n-length(ev_shrink)))
  }else if( method == "gcShrink"){
    suppressWarnings({
    res = gcShrink(t(X), var=1, cor=1, plot=FALSE)
    })
    lambda = res$optimalpha
    ev_gc = ev*(1-lambda) + lambda
    ev_hat = c(ev_gc, rep(lambda, n-length(ev_gc)))
  }else if( method == "ShrinkCovMat"){
  
    res = shrinkcovmat.identity(t(X), centered=FALSE)
    lambda_hat = res$lambdahat

    ev_shrink2 = (ev*(1-lambda_hat) + lambda_hat)
    ev_hat = c(ev_shrink2, rep(lambda_hat, n-length(ev_shrink2)))
  }else if( method == "ShrnkSigE"){

    res = ShrnkSigE( df=p-1, n, min(n,p-1), Sigma=cor(X), Trgt = "Idntty")
    lambda = ifelse("Intst" %in% names(res), res$Intst, 0)

    ev_gc = ev*(1-lambda) + lambda
    ev_hat = c(ev_gc, rep(lambda, n-length(ev_gc)))
  }else if(method == "rlogDet"){
    ev_hat = rlogDet(X)
  }else if(method == "population"){
    ev_hat = ev
  }else{
    stop("Method not found")
  }

  ev_hat
}


# 
useFast = FALSE
# n = 1000
p_array = c(seq(50, 100, by=20), seq(120,300, by=30))
# n_array = c(seq(4, 1500, by=100), seq(2000, 10000, by=500))
n_array = c(seq(4, 1000, by=100))


res = lapply( n_array, function(n){
  cat("\rn = ", n, '      ')
  res = lapply( p_array, function(p){

    if( useFast ){
      # construct data from eigen values
      # evTrue = eigen(Sigma)$values
      evTrue = sort(runif(n, 1, 1), decreasing=TRUE)
      Q <- clusterGeneration:::genOrthogonal(n) 
      # Sigma <- Q %*% diag(evTrue) %*% t(Q)
      # evTrue[1:3]
      # 
      # R = t(Q %*% (t(Q) * sqrt(pmax(evTrue, 0))))
      R = crossprod(sweep(Q, 1, evTrue,FUN="*"), Q)

      X = matrnorm(p, n) %*% R
      # crossprod(X)/p

    }else{
      # Generate correlation directly
      Sigma = cov2cor(genPositiveDefMat(n, ratioLambda=100, lambdaLow=30)$Sigma)
      evTrue = eigen(Sigma)$values
      X = mvtnorm::rmvnorm(p, sig=Sigma)
    }
   
    # logDet
    res = data.frame( n = n,
                      p = p,
                      True          = sum(log(evTrue)),
                      Population    = sum(log(estLogDet(X, "population"))),
                      # Strimmer      = sum(log(estLogDet(X, "Strimmer"))),
                      Strimmer       = rlogDet(X, "Strimmer"),
                      Touloumis       = rlogDet(X, "Touloumis"))
                      # gcShrink      = sum(log(estLogDet(X, "gcShrink"))),
                      # ShrinkCovMat  = sum(log(estLogDet(X, "ShrinkCovMat"))))
                      # ShrnkSigE     = sum(log(estLogDet(X, "ShrnkSigE"))))
    res

  })
  res = do.call(rbind, res)
})
res = do.call(rbind, res)

res2 = res
idx = colnames(res2) %in% c('n', 'p', 'True')
res2 = cbind(n=res2$n, p=res2$p, (res2[,!idx] - res$True))
df = melt(res2, id.vars=c('n', 'p'))

pdf("~/www/mvIC.pdf")
ggplot(subset(df, variable!="Population"), aes(n, value, color=variable)) + geom_point() + theme_bw() + theme(aspect.ratio=1) + ylab("Percent error") + facet_wrap(~p)
dev.off()




fig1 = ggplot(res, aes(True, Strimmer)) + geom_point( ) + theme_bw() + theme(aspect.ratio=1) + ylab("Percent error")
fig2 = ggplot(res, aes(True, Touloumis)) + geom_point( ) + theme_bw() + theme(aspect.ratio=1) + ylab("Percent error")

plot_grid(fig1, fig2)












# plot(evTrue, ylim= range(c(evTrue, ev, ev_shrink, ev_gc)))
# points(ev,col="red")
# points(ev_shrink,col="blue")
# points(ev_gc,col="green")

# logDet
sum(log(evTrue))
sum(log(ev[1:(p-1)]))
sum(log(ev_shrink))
sum(log(ev_gc))
rlogDet( X )


sum(log(ev_shrink2))





target = diag(1,n)

obj = optimize( function(alpha) logML(t(X), target, alpha), interval=c(1e-6, 1-1e-6), tol=1e-6, maximum=TRUE)





phase2_formula <- "~Dx.Tissue + (1 | Individual_ID) + RIN2 + (1 | Institution) + ageOfDeath + RIN + PMI + EV.1 + (1 | Reported_Gender) + EV.2 + EV.3 + EV.4"
phase3 <- mvIC::mvForwardStepwise(exprObj = subset_CQN[1:10,],
                         baseFormula = phase2_formula, 
                         data = COVARIATES,
                         variables = array(c("scale(IntragenicRate)", "scale(IntronicRate)","IntergenicRate)","scale(rRNARate)", "scale(TotalReads)", "scale(GenesDetected)", "scale(MappedReads)")))


y = subset_CQN[1,]
phase2_formula <- "y~Dx.Tissue + (1 | Individual_ID) + RIN2 + (1 | Institution) + ageOfDeath + RIN + PMI + EV.1 + (1 | Reported_Gender) + EV.2 + EV.3 + EV.4 + scale(TotalReads)"

fit = lme4::lmer(phase2_formula, COVARIATES)


--->













